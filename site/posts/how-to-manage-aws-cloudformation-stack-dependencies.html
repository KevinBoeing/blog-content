<p>AWS provides its own service for managing resource stacks: AWS&nbsp;CloudFormation. What are the options to manage dependencies between stacks, how to use them and which pros&nbsp;&amp;&nbsp;cons they have?</p>

<p>In general, we have three options how to link resources from different stacks:</p>
<p> </p>
<ul>
<li><strong>hard-coded</strong> in template code&nbsp;</li>
<li>via <strong>stack parameters</strong></li>
<li>via <strong>exports/imports</strong></li>
</ul>
<p> </p>
<h2>Hard-Coded References</h2>
<p>This is the most trivial variant as well as the most disadvantageous one. Let's say, the stack&nbsp;B needs a resource from the stack&nbsp;A:</p>
<pre class="brush: yaml">// stackA.yml

ServiceA:
  Type: AWS::Lambda::Function
  Properties:
    FunctionName: "service-A"
    ...

// stackB.yml

ServiceB:
  Type: AWS::Lambda::Function
  Properties:
    FunctionName: "service-B"
    Environment:
      Variables:
        SERVICE_A: "service-A"
    ...</pre>
<p>Well, at least the dependency is set via an environment variable (it could be worse: the reference could be hard-coded direct in the function code), but it's still very impractical. The value of the variable must be changed either via a template code change, or manually, which breaks principles of Continuous Delivery. The service B is not informed about a potential change in the stack&nbsp;A, there is no validation that the dependency actually exists and is correct. A system built in this way is obviously brittle and can stop working anytime.</p>
<h2>Stack Parameters&nbsp;</h2>
<p>Setting references via stack parameters is not very different from hard-coded values, but it's definitely a&nbsp;small progress, because <strong>we can change parameter values via our continuous delivery process</strong> (pipeline). But there is still no guarantee that the value is correct.</p>
<pre class="brush: yaml">// stackA.yml

Resources:
  ServiceA:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: "service-A"
      ...

Outputs:
  ServiceA:
    Description: "Service A."
    Value: !Ref ServiceA

// stackB.yml

Parameters:
  ServiceA:
    Type: String
    Description: "Reference to the Service A"

Resources:
  ServiceB:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: "service-B"
      Environment:
        Variables:
          SERVICE_A: !Ref ServiceA
      ...</pre>
<p>Because the stack&nbsp;A publishes the service A in its outputs, we can set the value even in an automation manner. But the problem with inconsistence, in case the resources has changed, remains.&nbsp;</p>
<h2>Exports/Imports</h2>
<p>The most secure way how to deal with stack dependencies in AWS CloudFormation is to use exports/imports. The exported (and somewhere imported) r<strong>esources are protected from changes</strong> and we get a handy overview of our dependencies out of the box.</p>
<pre class="brush: yaml">// stackA.yml

Resources:
  ServiceA:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: "service-A"
      ...

Outputs:
  ServiceA:
    Description: "Service A."
    Value: !Ref ServiceA
    Export:
      Name: "ServiceA"

// stackB.yml

Resources:
  ServiceB:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: "service-B"
      Environment:
        Variables:
          SERVICE_A: !ImportValue "ServiceA"
      ...</pre>
<p>Now, any <strong>change of the exported value will cause an integrity error</strong> and so we can be sure that our dependencies are always correct.&nbsp;</p>
<h2>Parameterized Exports/Imports</h2>
<p>The approach above is fine for small systems with only few stacks. As our system grows there are more and more stacks and we can easily lose the overview which resource belongs to which stack. A good practice here is to use the stack names as &quot;namespaces&quot; to group all the stack resources under the same prefix:</p>
<pre class="brush: yaml">// stackA.yml

Resources:
  ServiceA:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${AWS::StackName}-service-A-${AWS::Region}"
      ...

Outputs:
  ServiceA:
    Description: "Service A."
    Value: !Ref ServiceA
    Export:
      Name: !Sub "${AWS::StackName}-ServiceA"</pre>
<p>The question is, how to pass the name of the exported variable? We can hard-code it, but it will couple the template code with the stack name, which is&nbsp;undesirable, because the code shouldn't have any knowledge how stacks are deployed - named.</p>
<p>Another option is to pass variable names as stack parameters, which could work fine, but it means hard and unnecessary effort, because, all in all, the <strong>names are part of the stack&nbsp;API and therefore mustn't change</strong> (only the stack name is variable).</p>
<p>The&nbsp;compromise is to <strong>pass only the stack name as a parameter</strong>:&nbsp;</p>
<pre class="brush: yaml">// stackB.yml

Parameters:
  StackNameA:
    Type: String
    Description: "Name of the Stack A"

Resources:
  ServiceB:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: "service-B"
      Environment:
        Variables:
          SERVICE_A:
            Fn::ImportValue: {"Fn::Sub": "${StackNameA}-ServiceA"}
      ...</pre>
<p>With this approach we have all the benefits of <strong>exports/imports integrity</strong> while&nbsp;<strong>variability and deployment independence</strong> is preserved.</p>
<p>Happy infrastructure coding!</p>
