<p><a href="https://blog.ttulka.com/learning-webassembly-series" target="_blank">WebAssembly</a> (Wasm) describes a memory-safe, sandboxed execution environment. Wasm modules are pieces of bytecode that can be written in and compiled from a bright scale of programming languages (C/C++, Rust, Go, <a href="https://blog.ttulka.com/learning-webassembly-9-assemblyscript-basics">AssemblyScript</a>, and many others).</p>

<p>These characteristics make Wasm an ideal candidate for an open and very lightweight serverless computing platform.</p>

<p><em>Nanoprocesses</em> coined in the <a href="https://hacks.mozilla.org/2019/11/announcing-the-bytecode-alliance/" target="_blank">Bytecode Alliance announcement</a> are a theoretical concept of very lightweight sandboxed fibers spawned and running within a single operating system (OS) process. Nanoprocesses are not real OS processes so they don’t come with their expensive overheads yet are sandboxed and isolated from each other.</p>

<p class="note">There are already production-ready Wasm serverless computing solutions such as <a href="https://wasmedge.org/" target="_blank">WasmEdge</a>, <a href="https://wasmcloud.dev/" target="_blank">wasmcloud</a>, and <a href="https://krustlet.dev/" target="_blank">Krustlet</a> but they do not seem to have implemented the concept of nanoprocesses so far. <a href="https://github.com/suborbital/atmo" target="_blank">Atmo</a> is a promising project that has been on the right track.<br><br>Our aim is, however, to explore the concept by implementing a simple working solution from scratch.</p>

<h2>Requirements</h2>

<p>Our Wasm platform should meet all standard requirements on today’s serverless computing platforms such as AWS Lambda:</p>

<ul>
  <li>No operational overheads</li>
  <li>Pay as you go</li>
  <li>Run in isolation</li>
  <li>Resource limiting</li>
  <li>Scalability</li>
  <li>High availability</li>
</ul>

<p>As Wasm is sandboxed per default, we get a good level of isolation for free. The platform must take care of the rest.</p>

<h2>Wasm Modules</h2>

<p>To simplify things to the maximum, we will write Wasm modules in <a href="https://blog.ttulka.com/learning-webassembly-3-wat-programming-basics" target="_blank">Wasm text format</a> (WAT). Our modules are simple enough to do that but any language will work as WebAssembly is a portable binary format.</p>

<p>Consider these three Wat files:</p>

<pre>
;; answer.wat
(module
  (func (export "_start")
        (result i32)
    i32.const 42
    return))
</pre>
<pre>
;; sum.wat
(module
  (func (export "_start")
        (param $a i32)
        (param $b i32)
        (result i32)
    local.get $a
    local.get $b
    i32.add
    return))
</pre>
<pre>
;; sleep.wat
(module
  (import "platform" "now" (func $now (result f64)))
  (func (export "_start")
        (local $target i64)
    i64.const 3000
    (i64.trunc_f64_s (call $now))
    i64.add
    local.set $target
    loop $loop
      (i64.trunc_f64_s (call $now))
      local.get $target
      i64.lt_s
    br_if $loop
    end))
</pre>

<p>The first module returns the number 42 as the <a href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_(42)" target="_blank">ultimate answer</a>, the second returns the sum of two integers, and finally, the third module blocks execution for three seconds (active waiting).</p>

<p>We can compile Wat files to Wasm with the <a href="https://github.com/webassembly/wabt" target="_blank">WebAssembly Binary Toolkit</a>:</p>

<pre>
$ wat2wasm answer.wat -o answer.wasm
</pre>

<h2>Wasm in Node.js</h2>

<p>Our modules come with no dependencies except the <code>sleep</code> module which requires a function to get the actual time in milliseconds.</p>

<p>We import all the platform dependencies via an import object <code>platform</code>:</p>

<pre class="brush: javascript">
// run.js
const fs = require(&#39;fs&#39;);
WebAssembly.instantiate(
  fs.readFileSync(process.argv[2]),
  {
    platform: {
      now: Date.now
    }
  }
).then(({instance: {exports: wasm}}) =&gt; {
  const params = process.argv.slice(3);
  const res = wasm._start(...params);
  console.log(res);
});
</pre>

<p>We can then run any module with Node.js:</p>

<pre>
$ node run.js sum.wasm 5 2
7
</pre>

<p>We will reuse this code later as a Wasm executor in the platform.</p>

<h2>Platform API</h2>

<p>We will use a very simple HTTP server with the following endpoints:</p>

<ul>
  <li><code>/register/&lt;module&gt;</code> - registers a module to the platform</li>
  <li><code>/exec/&lt;module&gt;[?param1[,param2[...]]]</code> - executes a registered module</li>
  <li><code>/stats/&lt;module&gt;</code> - module execution stats (consumed time, etc.)</li>
</ul>

<h2>Thread Worker Execution</h2>

<p>In Node.js, Wasm modules are executed synchronously in the single program thread:</p>

<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/wasm-serverless/wasm-serverless-1.png"></p>

<p>This means that we cannot execute multiple modules in parallel which could lead to higher latency on a single node. Every request must wait until the previous one ends:</p>

<pre>
$ time curl http://localhost:8000/exec/sleep &
3.048s
$ time curl http://localhost:8000/exec/sleep &
5.986s
</pre>

<p>Another problem with this approach is that we cannot really control the Wasm execution as the execution flow is overtaken by the Wasm module.</p>

<p>The good news is we can solve this problem with <a href="https://nodejs.org/api/worker_threads.html" target="_blank">worker threads</a>. We will maintain a worker thread pool of reusable threads and execute modules on idle workers:</p>

<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/wasm-serverless/wasm-serverless-2.png"></p>

<p>Now, multiple modules can be executed in parallel without blocking:</p>

<pre>
$ time curl http://localhost:8000/exec/sleep &
3.042s
$ time curl http://localhost:8000/exec/sleep &
3.039s
</pre>

<h2>Cold Start Optimization</h2>

<p>The initial downloading/loading of the Wasm file could take a while. This is called a cold start and it is good practice to avoid it for frequently executed modules.</p>

<p>We can optimize cold starts by introducing caching of already executed modules. Module binaries would be kept in the memory for an amount of time. Modules executed within this period will avoid cold starts:
</p>

<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/wasm-serverless/wasm-serverless-3.png"></p>

<p>Consider cache eviction after one second. When the same module execution is requested less than one second after the last one, the latency will be slightly improved:</p>

<pre>
$ curl http://localhost:8000/exec/sleep &
# after less than a second:
$ curl http://localhost:8000/exec/sleep &
$ curl http://localhost:8000/stats/sleep
execution time: 6061ms

$ curl http://localhost:8000/exec/sleep
# after more than a second:
$ curl http://localhost:8000/exec/sleep
$ curl http://localhost:8000/stats/sleep
execution time: 6093ms
</pre>

<p>We saved some time on the cold start and time means money in the pay-as-you-go pricing model!</p>

<p class="note">In Node.js, one cannot, unfortunately, share functions among threads. Therefore it is not possible to cache loaded and initialized Wasm module which would otherwise be a great performance improvement.</p>

<h2>Resource Limits</h2>

<p>It is very easy to limit memory usage for a Wasm module simply by importing a demanded amount of memory into the module:</p>

<pre>
await WebAssembly.instantiate(wasmBuffer, {
  ...importObject,
  memory: new WebAssembly.Memory({initial: PAGES})
});
</pre>

<p>At the time of writing, Wasm is single-threaded, so we don’t have to worry about consuming CPU cores. However, we should definitely limit the consumption of CPU time by introducing execution timeouts:</p>

<p align="center"><img src="https://raw.githubusercontent.com/ttulka/blog-assets/master/wasm-serverless/wasm-serverless-4.png"></p>

<h3>Execution Timeout</h3>

<p>Because we don’t control the Wasm code directly there is nothing to prevent malicious users from writing a Wasm module with an infinite loop that eventually gets the platform stuck:</p>

<pre>
;; stuck.wat
(module
  (func (export "_start")
    loop $loop
    br $loop
    end))
</pre>

<p>We should include some kind of timeout mechanism that terminates the execution after an arbitrary duration has been reached.</p>

<p>As far as there is no way to interrupt a running Wasm instance there is not much we can do about execution timeout. We can think of implementing timeout checks directly into the virtual machine (VM) but this would be quite an exhausting effort.</p>

<p>The one option left is to terminate the executing worker:</p>

<pre>
setTimeout(() => worker.terminate(),
    EXECUTION_TIMEOUT_MS);
</pre>

<p>So we can limit execution resources without using any advanced technology such as containers (cgroups).</p>

<p class="note">Needless to say, even containers are not the recommended way to run untrusted code as they don’t really provide 100% isolation. If security is an issue, a VM-based solution should be considered instead.</p>

<h2>Conclusion</h2>

<p>Our platform is up and running. How far did we get? Let’s see if we could fulfill all requirements:</p>

<p>
<table border="1" cellspacing="0" cellpadding="5" width="100%">
  <tr><th>Requirement</th><th>Solution</th><th>Achieved</th></tr>
  <tr><td>No operational overheads</td><td>Portable Wasm modules</td><td>yes</td></tr>
  <tr><td>Pay as you go</td><td>Execution time measurements</td><td>yes</td></tr>
  <tr><td>Run in isolation</td><td>Linear memory, Wasm VM sandbox</td><td>yes</td></tr>
  <tr><td>Resource limiting</td><td>Linear memory, single-threaded execution, timeouts</td><td>yes</td></tr>
  <tr><td>Scalability</td><td>Worker pool</td><td>yes</td></tr>
  <tr><td>High availability</td><td>Multiple instances of the platform possible</td><td>yes</td></tr>
</table>
</p>

<p>It seems that all the goals were achieved or are at least possible to achieve. By using Wasm modules as the computing function format we gain a lot of features for free. Many of them like isolation would otherwise be hard to get without using some advanced technology such as containers.</p>

<p>Moreover, platform maintenance is extremely easy because we don’t have to consider multiple runtimes in order to support different programming languages.</p>

<p>WebAssembly universal bytecode format has a bright future in computing platforms and we will definitely see many of these around very soon.</p>

<p>Source code (barely 300 lines) can be found on <a href="https://github.com/ttulka/wasm-severless-from-scratch" target="_blank">my GitHub</a>.</p>

<p>Happy computing!</p>

